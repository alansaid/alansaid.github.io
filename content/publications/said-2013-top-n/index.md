---
title: A Top-N Recommender System Evaluation Protocol Inspired by Deployed Systems
type: publication 
profile: false
# Authors
# A YAML list of author names
# If you created a profile for a user (e.g. the default `admin` user at `content/authors/admin/`), 
# write the username (folder name) here, and it will be replaced with their full name and linked to their profile.
authors:
- alan
- Alejandro Bellog√≠n Kouki
- Arjen de Vries

# Author notes (such as 'Equal Contribution')
# A YAML list of notes for each author in the above `authors` list
author_notes: []

date: '2013-10-01'

# Date to publish webpage (NOT necessarily Bibtex publication's date).
publishDate: '2023-12-23T22:33:31.126943Z'

# Publication type.
# A single CSL publication type but formatted as a YAML list (for Hugo requirements).
publication_types:
- paper-conference

# Publication name and optional abbreviated publication name.
publication: '*ACM RecSys Workshop on Large-Scale Recommender Systems*'
publication_short: ''

doi: ''

abstract: The evaluation of recommender systems is crucial for their development.
  In today's recommendation landscape there are many standardized recommendation algorithms
  and approaches, however, there exists no standardized method for experimental setup
  of evaluation -- not even for widely used measures such as precision and root-mean-squared
  error. This creates a setting where comparison of recommendation results using the
  same datasets becomes problematic. In this paper, we propose an evaluation protocol
  specifically developed with the recommendation use-case in mind, i.e. the recommendation
  of one or several items to an end user. The protocol attempts to closely mimic a
  scenario of a deployed (production) recommendation system, taking specific user
  aspects into consideration and allowing a comparison of small and large scale recommendation
  systems. The protocol is evaluated on common recommendation datasets and compared
  to traditional recommendation settings found in research literature. Our results
  show that the proposed model can better capture the quality of a recommender system
  than traditional evaluation does, and is not affected by characteristics of the
  data (e.g. size. sparsity, etc.).

# Summary. An optional shortened abstract.
summary: ''

tags: []

# Display this page in a list of Featured pages?
featured: false

# Links
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

# Publication image
# Add an image named `featured.jpg/png` to your page's folder then add a caption below.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects: ['internal-project']` links to `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []
links:
- name: URL
  url: https://ir.cwi.nl/pub/21489
---


